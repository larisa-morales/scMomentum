{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import csv\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib import colors\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import multiprocessing\n",
    "import networkx as nx\n",
    "import numba\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "from random import choices\n",
    "import re\n",
    "import scipy as scp\n",
    "import scipy.integrate as integrate\n",
    "from scipy.special import hyp2f1 as hyper\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm as normal\n",
    "import scvelo as scv\n",
    "from scvelo.tools.velocity_embedding import quiver_autoscale,velocity_embedding\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import Birch\n",
    "import sklearn.decomposition as skd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import string\n",
    "import umap\n",
    "import skbio as sk\n",
    "scv.settings.verbosity = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_adata(file):\n",
    "    \n",
    "    # INPUT\n",
    "    # file = path to file containing a pickle object\n",
    "    # OUTPUT\n",
    "    # AnnData object\n",
    "    \n",
    "    with open(file, 'rb') as inF:\n",
    "        obj = pickle.load(inF)\n",
    "        \n",
    "        return(obj)\n",
    "    \n",
    "def save_adata(obj, filename):\n",
    "    \n",
    "    # IPUT\n",
    "    # obj = python object\n",
    "    # filename = path to save object\n",
    "\n",
    "    with open(filename, 'wb') as output: \n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def unique(list1): \n",
    "    \n",
    "    # INPUT\n",
    "    # list1 = python list\n",
    "    # OUTPUT:\n",
    "    # numpy array with unique elements in the list\n",
    "    \n",
    "    x = np.array(list1) \n",
    "    return(np.unique(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(df):\n",
    "    \n",
    "    # INPUT\n",
    "    # df =  distance matrix data frame\n",
    "    # OUTPUT\n",
    "    # scaled_df = scaled distance matrix\n",
    "    \n",
    "    scaled_df = df\n",
    "    values = []\n",
    "    for i in range(0,len(df.index)):\n",
    "        for j in range(i,len(df.columns)):\n",
    "            values.append(df.iloc[i,j])\n",
    "\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(np.array(values).reshape(-1, 1))\n",
    "\n",
    "    k=0\n",
    "    for i in range(0,len(df.index)):\n",
    "        for j in range(i,len(df.columns)):\n",
    "            scaled_df.iloc[i,j]=x_scaled[k]\n",
    "            scaled_df.iloc[j,i]=x_scaled[k]\n",
    "            k=k+1\n",
    "    return(scaled_df)\n",
    "\n",
    "def expression_distance(adata,resc=True,copy=False):\n",
    "    \n",
    "    # INPUT\n",
    "    # adata - AnnData object\n",
    "    # clustcol - name of the column used to cluster cells \n",
    "    # resc - whether to normalize and rescale distances (recommended)\n",
    "    # copy - whether a copy of the distance matrix should be returned. By default copy=True and adata.uns['expression_distances'] is updated\n",
    "\n",
    "    clusters = [c for c in adata.obs.dropna()[clustcol].unique() if c!='nan']\n",
    "    centroids = [np.array(np.mean(adata.layers['spliced'][(adata.obs[clustcol] == c).values,:],axis=0)[:,].tolist()[0]) for c in clusters]\n",
    "\n",
    "\n",
    "    nc = len(centroids)\n",
    "    dist = pd.DataFrame(0,index=range(0,nc),columns=range(0,nc),dtype=np.float64)\n",
    "    for i in range(0,nc):\n",
    "        for j in range(i,nc):\n",
    "            dist.at[i,j] = np.linalg.norm(centroids[i] - centroids[j])\n",
    "            dist.at[j,i] = dist.at[i,j]\n",
    "            \n",
    "    if(resc):\n",
    "        dist = rescale(dist)\n",
    "        \n",
    "    dist = sk.DistanceMatrix(dist.values)\n",
    "    \n",
    "    if copy==False:\n",
    "        adata.uns['expression_distances'] = dist\n",
    "    else:\n",
    "        return(dist)\n",
    "\n",
    "def preprocess(adata):\n",
    "    \n",
    "    # Compute cluster distances \n",
    "    \n",
    "    expression_distance(adata)\n",
    "    \n",
    "    # Remove genes with NaN's in velocity\n",
    "        \n",
    "    V = adata.layers[\"velocity\"]\n",
    "    genes_valid = adata.var[['velocity_genes']].iloc[np.where(np.logical_not(np.isnan(V.sum(axis=0))))[0].tolist(),:].index\n",
    "    adata_valid = adata[:,genes_valid]\n",
    "    adata_valid.var['gtype'] = 'Velocity_not_nan'\n",
    "    \n",
    "    return(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_genes(V,X,n,m):\n",
    "    \n",
    "    # INPUT\n",
    "    # V = velocity matric for the cells in a specific cluster\n",
    "    # X = expression matrix for the cells in a specific cluster\n",
    "    # n = number of genes to choose\n",
    "    # m = str ranking method. Options:\n",
    "    #   * absvel = gene ranking based on the mean (across cells) absolute value of velocity \n",
    "    #   * topvel = gene ranking based on the mean (across cells) value of velocity (including sign)\n",
    "    #   * stdvel = gene ranking based on decreasing standard deviation of velocity across cells\n",
    "    #   * random = gene set selected at random\n",
    "    #   * stdexp = gene ranking basedon decreasing standard deviation of expression across cells\n",
    "    #   * highexp = gene ranking basedon decreasing expression level across cells\n",
    "    # OUTPUT\n",
    "    # genes = list with genes selected (based on the cluster matrix dimensions) \n",
    "    \n",
    "    if(mode=='absvel'):\n",
    "        genes = v.dropna().abs().mean(0).sort_values(ascending=False)[0:n].index.tolist()\n",
    "    elif(mode=='topvel'):\n",
    "        genes = v.dropna().mean(0).sort_values(ascending=False)[0:n].index.tolist()\n",
    "    elif(mode=='stdvel'):\n",
    "        genes = v.dropna().std(0).sort_values(ascending=False).index.tolist()[0:n]\n",
    "    elif(mode=='stdexp'):        \n",
    "        genes = xm.dropna().std(0).sort_values(ascending=False).index.tolist()[0:n]\n",
    "    elif(mode=='highexp'):\n",
    "        genes = xm.dropna().mean(0).sort_values(ascending=False).index.tolist()[0:n]\n",
    "\n",
    "    return(genes)\n",
    "\n",
    "\n",
    "def predict_network(adata,cluster,genes,network_size,copy=False):\n",
    "\n",
    "    ## INPUT \n",
    "    \n",
    "    # clustcol - cluster column used\n",
    "    # cluster - individual cluster label\n",
    "    # genes - either a str (vrank,maxstd,topvar,abstop,random) or a list of genes (same as in adata.var.index) \n",
    "    # network_size - number of genes used to infer the network\n",
    "    # copy - whether a copy of the network should be returned. By default copy=True\n",
    "    \n",
    "    ## OUTPUT\n",
    "    \n",
    "    ind = adata.obs[clustcol] == cluster\n",
    "    \n",
    "    #Velocity matrix\n",
    "    V = pd.dataFrame(adata.layers[\"velocity\"][ind.values,:],columns=adata.var.index)\n",
    "    \n",
    "    #Expression matrix\n",
    "    X = pd.dataFrame(adata.layers['spliced'][ind.values,:].todense(),columns=adata.var.index)\n",
    "\n",
    "    #Get requested genes\n",
    "    \n",
    "    if isinstance(genes,str):\n",
    "        genes = rank_genes(V,X,genes,network_size)\n",
    "    \n",
    "\n",
    "    #Filter matrices for model reconstruction \n",
    "    \n",
    "    genes = [g for g in fg if g in X.columns]\n",
    "    Xc = X.loc[:,genes] # cell by gene expression matrix\n",
    "    Xpinv = np.linalg.pinv(Xc) # gene by cell expression matrix\n",
    "    Vc = V.loc[:,genes] # cell by gene velocity matrix\n",
    "    Gf = np.diag(adata.var.fit_gamma.loc[genes,]) # gene by gene diagonal gamma matrix\n",
    "    \n",
    "    \n",
    "    W = np.nan_to_num(np.dot(Xpinv,(Vc + np.dot(Xc,Gf))),nan=0) \n",
    "    W = pd.DataFrame(np.array(W,dtype=np.float64),index=fg,columns=fg)\n",
    "    \n",
    "    W.index,W.columns = genes,genes\n",
    "    \n",
    "    return(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_network(adata,cluster='Neuron',genes=100,network_size,copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Immature_neuron', 'Neuroblast', 'Neuron', 'Radial_glia'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(adata.obs[clustcol])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene selection\n",
    "\n",
    "Functions to run testing of user-specified combinations of gene sets and network sizes. Networks are not stored at this step, only the list of the top `n` combinations (according to the mantel correlation will be stored in adata.uns as `top_gene_sets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_network_mode(adata,clustcol,genes,network_size):\n",
    "    \n",
    "    \n",
    "    clusts = [c for c in adata.obs.dropna()[clustcol].unique() if c!='nan']\n",
    "    W_list = [predict_network(adata,clustcol,c,genes,network_size,copy=True) for c in clusts]\n",
    "    \n",
    "    # Calculate mantel correlation between distance matrices\n",
    "    net_dist = cdm_computeDistance(W_list,resc=True,dis_type='euclidean')\n",
    "    coeff,p_value,_ = sk.stats.distance.mantel(net_dist,adata.uns['cluster_centroid_distances'])\n",
    "    \n",
    "    results = [dset_name,method,ngenes,exp_tf,coeff,p_value]\n",
    "    \n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters\n",
    "\n",
    "global dset,clustcol\n",
    "dset = 'hFB18'\n",
    "clustcol = 'labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load adata\n",
    "\n",
    "adata_dir = \"/Users/larisamorales/Documents/KAUST/scgrn-project/objects/\"\n",
    "adata_path = adata_dir + \"scvelo/\" + dset + \"-adata.pkl\"\n",
    "adata = load_adata(adata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to set attribute `.var` of view, copying.\n"
     ]
    }
   ],
   "source": [
    "adata = preprocess(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
