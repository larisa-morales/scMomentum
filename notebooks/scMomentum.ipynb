{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scMomentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import csv\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib import colors\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import multiprocessing\n",
    "import networkx as nx\n",
    "import numba\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "from random import choices\n",
    "import re\n",
    "import scipy as scp\n",
    "import scipy.integrate as integrate\n",
    "from scipy.special import hyp2f1 as hyper\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm as normal\n",
    "import scvelo as scv\n",
    "from scvelo.tools.velocity_embedding import quiver_autoscale,velocity_embedding\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import Birch\n",
    "import sklearn.decomposition as skd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import string\n",
    "import umap\n",
    "scv.settings.verbosity = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_adata(file):\n",
    "    \n",
    "    # Input: \n",
    "    #  - file = path to file containing a pickle object\n",
    "    # Returns:\n",
    "    #  - loaded data in the original format\n",
    "    \n",
    "    with open(file, 'rb') as inF:\n",
    "        obj = pickle.load(inF)\n",
    "        \n",
    "        return(obj)\n",
    "    \n",
    "def save_adata(obj, filename):\n",
    "    \n",
    "    # Input:\n",
    "    #   - obj = python object\n",
    "    #   - filename = path to save object\n",
    "    # Returns:\n",
    "    #   - nothing, just saves the object into the specified file \n",
    "    \n",
    "    with open(filename, 'wb') as output: \n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def unique(list1): \n",
    "    \n",
    "    # Input:\n",
    "    #  - list1 = python list\n",
    "    # Returns:\n",
    "    #  - numpy array with unique elements in the list\n",
    "    \n",
    "    x = np.array(list1) \n",
    "    return(np.unique(x))\n",
    "\n",
    "def pad_matrix(n,m):\n",
    "    A=scp.sparse.csr_matrix((n*m,n*m),dtype=float)\n",
    "    for i in range(n*m):\n",
    "        \n",
    "        if i==0:\n",
    "            A[i,i+1]=1/3\n",
    "            A[i,i+m]=1/3\n",
    "            A[i,i+m+1]=1/3\n",
    "        elif i==m-1:\n",
    "            A[i,i-1]=1/3\n",
    "            A[i,i+m-1]=1/3\n",
    "            A[i,i+m]=1/3\n",
    "        elif i==(n-1)*m:\n",
    "            A[i,i-m]=1/3\n",
    "            A[i,i-m+1]=1/3\n",
    "            A[i,i+1]=1/3\n",
    "        elif i==n*m-1:\n",
    "            A[i,i-m-1]=1/3\n",
    "            A[i,i-m]=1/3\n",
    "            A[i,i-1]=1/3\n",
    "        elif i<m:\n",
    "            A[i,i-1]=1/5\n",
    "            A[i,i+1]=1/5\n",
    "            A[i,i+m-1]=1/5\n",
    "            A[i,i+m]=1/5\n",
    "            A[i,i+m+1]=1/5\n",
    "        elif i>(n-1)*m:\n",
    "            A[i,i-m-1]=1/5\n",
    "            A[i,i-m]=1/5\n",
    "            A[i,i-m+1]=1/5\n",
    "            A[i,i-1]=1/5\n",
    "            A[i,i+1]=1/5\n",
    "        elif i%m==0:\n",
    "            A[i,i-m]=1/5\n",
    "            A[i,i-m+1]=1/5\n",
    "            A[i,i+1]=1/5\n",
    "            A[i,i+m]=1/5\n",
    "            A[i,i+m+1]=1/5\n",
    "        elif i%m==(-1%m):\n",
    "            A[i,i-m-1]=1/5\n",
    "            A[i,i-m]=1/5\n",
    "            A[i,i-1]=1/5\n",
    "            A[i,i+m-1]=1/5\n",
    "            A[i,i+m]=1/5\n",
    "        else:\n",
    "            A[i,i-m-1]=1/8\n",
    "            A[i,i-m]=1/8\n",
    "            A[i,i-m+1]=1/8\n",
    "            A[i,i-1]=1/8\n",
    "            A[i,i+1]=1/8\n",
    "            A[i,i+m-1]=1/8\n",
    "            A[i,i+m]=1/8\n",
    "            A[i,i+m+1]=1/8\n",
    "    return A\n",
    "\n",
    "def soften(Z,it=2,ep=None):\n",
    "    if ep:\n",
    "        err=ep+1\n",
    "        while err>ep:\n",
    "            Zp=Z\n",
    "            Z=padMatrix(Z.shape[0],Z.shape[1]).dot(np.ravel(Z)).reshape(Z.shape)\n",
    "            err=(Z-Zp).max()\n",
    "            print(err)\n",
    "        return Z\n",
    "    else:\n",
    "        for i in range(it):\n",
    "            Z=padMatrix(Z.shape[0],Z.shape[1]).dot(np.ravel(Z)).reshape(Z.shape)\n",
    "        return Z\n",
    "\n",
    "def sigmoide(cells,th=None):\n",
    "    if th is None:\n",
    "        th = np.mean(cells,0)\n",
    "    \n",
    "    sig = (cells-th)>0\n",
    "    \n",
    "    sig = sig*2-1\n",
    "    \n",
    "    return sig\n",
    "\n",
    "def project_velocity_on_grid(\n",
    "    adata,\n",
    "    cells_2d,\n",
    "    density=None,\n",
    "    smooth=None,\n",
    "    n_neighbors=None,\n",
    "    min_mass=None,\n",
    "    autoscale=True,\n",
    "    adjust_for_stream=False,\n",
    "    cutoff_perc=None,\n",
    "):\n",
    "    \n",
    "    T=scv.tools.transition_matrix(adata)\n",
    "    T.setdiag(0)\n",
    "    T.eliminate_zeros()\n",
    "    V_emb=np.zeros(cells_2d.shape)\n",
    "    densify = adata.n_obs < 1e4\n",
    "    TA = T.A if densify else None\n",
    "    for i in range(cells_2d.shape[0]):\n",
    "        indices = T[i].indices\n",
    "        dX = cells_2d[indices] - cells_2d[i, None]  # shape (n_neighbors, 2)\n",
    "        #if not retain_scale: dX /= norm(dX)[:, None]\n",
    "        dX /= scv.utils.norm(dX)[:,None]\n",
    "        dX[np.isnan(dX)] = 0  # zero diff in a steady-state\n",
    "        probs = TA[i, indices] if densify else T[i].data\n",
    "        V_emb[i] = probs.dot(dX) - probs.mean() * dX.sum(0)  # probs.sum() / len(indices)\n",
    "    \n",
    "    X_emb = cells2d\n",
    "    # remove invalid cells\n",
    "    idx_valid = np.isfinite(X_emb.sum(1) + V_emb.sum(1))\n",
    "    X_emb = X_emb[idx_valid]\n",
    "    V_emb = V_emb[idx_valid]\n",
    "    # prepare grid\n",
    "    n_obs, n_dim = X_emb.shape\n",
    "    density = 1 if density is None else density\n",
    "    smooth = 0.5 if smooth is None else smooth\n",
    "    grs = []\n",
    "    for dim_i in range(n_dim):\n",
    "        m, M = np.min(X_emb[:, dim_i]), np.max(X_emb[:, dim_i])\n",
    "        m = m - 0.01 * np.abs(M - m)\n",
    "        M = M + 0.01 * np.abs(M - m)\n",
    "        gr = np.linspace(m, M, int(50 * density))\n",
    "        grs.append(gr)\n",
    "    meshes_tuple = np.meshgrid(*grs)\n",
    "    X_grid = np.vstack([i.flat for i in meshes_tuple]).T\n",
    "    # estimate grid velocities\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int(n_obs / 50)\n",
    "    nn = NearestNeighbors(n_neighbors=n_neighbors, n_jobs=-1)\n",
    "    nn.fit(X_emb)\n",
    "    dists, neighs = nn.kneighbors(X_grid)\n",
    "    scale = np.mean([(g[1] - g[0]) for g in grs]) * smooth\n",
    "    weight = normal.pdf(x=dists, scale=scale)\n",
    "    p_mass = weight.sum(1)\n",
    "    V_grid = (V_emb[neighs] * weight[:, :, None]).sum(1)\n",
    "    V_grid /= np.maximum(1, p_mass)[:, None]\n",
    "    if min_mass is None:\n",
    "        min_mass = 1\n",
    "    if adjust_for_stream:\n",
    "        X_grid = np.stack([np.unique(X_grid[:, 0]), np.unique(X_grid[:, 1])])\n",
    "        ns = int(np.sqrt(len(V_grid[:, 0])))\n",
    "        V_grid = V_grid.T.reshape(2, ns, ns)\n",
    "        mass = np.sqrt((V_grid ** 2).sum(0))\n",
    "        min_mass = 10 ** (min_mass - 6)  # default min_mass = 1e-5\n",
    "        min_mass = np.clip(min_mass, None, np.max(mass) * 0.9)\n",
    "        cutoff = mass.reshape(V_grid[0].shape) < min_mass\n",
    "        if cutoff_perc is None:\n",
    "            cutoff_perc = 5\n",
    "        length = np.sum(np.mean(np.abs(V_emb[neighs]), axis=1), axis=1).T\n",
    "        length = length.reshape(ns, ns)\n",
    "        cutoff |= length < np.percentile(length, cutoff_perc)\n",
    "        V_grid[0][cutoff] = np.nan\n",
    "    else:\n",
    "        min_mass *= np.percentile(p_mass, 99) / 100\n",
    "        X_grid, V_grid = X_grid[p_mass > min_mass], V_grid[p_mass > min_mass]\n",
    "        if autoscale:\n",
    "            V_grid /= 3 * quiver_autoscale(X_grid, V_grid)\n",
    "    return X_grid, V_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_genes(v,xm,ng,mode):\n",
    "    \n",
    "    # Description:\n",
    "    # Selects genes used for network inference based on the chosen method.\n",
    "    # Input:\n",
    "    #   - v = velocity matric for the cells in a specific cluster\n",
    "    #   - xm = expression matrix for the cells in a specific cluster\n",
    "    #   - ng = number of genes to choose\n",
    "    #   - mode = selection method. Options:\n",
    "    #        * abstop = gene ranking based on the mean (across cells) absolute value of velocity \n",
    "    #        * ran = gene set selected at random\n",
    "    #        * top = gene ranking based on the mean (across cells) value of velocity (including sign)\n",
    "    #        * minstd = gene ranking based on increasing standard deviation of velocity across cells\n",
    "    #        * maxstd = gene ranking based on decreasing standard deviation of velocity across cells\n",
    "    #        * vrank = gene ranking based on differential velocity across clusters\n",
    "    #        * mark = cluster marker genes, specified in the object clusterMarkers, this options requires argument 'c' to be the name of the cluster\n",
    "    #        * leastvar = gene ranking basedon increasing standard deviation of expression across cells\n",
    "    #        * topvar = gene ranking basedon decreasing standard deviation of expression across cells\n",
    "    # Returns:\n",
    "    #   - pos = list with genes selected (based on the cluster matrix dimensions) \n",
    "    \n",
    "    ng = int(ng)\n",
    "    \n",
    "    if(mode=='abstop'):\n",
    "        pos = v.dropna().abs().mean(0).sort_values(ascending=False)[0:ng].index.tolist()\n",
    "    elif(mode=='ran'):\n",
    "        n = len(v.dropna().columns)\n",
    "        if(ng>=n):\n",
    "            pos = v.dropna().columns.tolist()\n",
    "        else:\n",
    "            pos = v.dropna().sample(ng,axis=1).abs().mean(0).index.tolist()\n",
    "    elif(mode=='top'):\n",
    "        pos = v.dropna().mean(0).sort_values(ascending=False)[0:ng].index.tolist()\n",
    "    elif(mode=='maxstd'):\n",
    "        pos = v.dropna().std(0).sort_values(ascending=False).index.tolist()[0:ng]\n",
    "    elif(mode == 'vrank'):\n",
    "        pos = V_rank[c][0:ng].tolist()\n",
    "    elif(mode=='topvar'):        \n",
    "        pos = xm.dropna().std(0).sort_values(ascending=False).index.tolist()[0:ng]\n",
    "    elif(mode=='highexp'):\n",
    "        pos = xm.dropna().mean(0).sort_values(ascending=False).index.tolist()[0:ng]\n",
    "\n",
    "    return(pos)\n",
    "\n",
    "def centroid_cells(X_arr,qu=0.65):\n",
    "    \n",
    "    # Input:\n",
    "    #   - X_arr = numpy array, gene expression data of a cluster\n",
    "    #   - qu = quantile to filter distance of cells, default 0.65\n",
    "    # Output:\n",
    "    #  - list with index of cells \n",
    "    centroid = np.array([X_arr.mean(1)]).T\n",
    "    dists = np.sqrt(np.sum(np.power(X_arr-centroid,2),axis=0))\n",
    "    quant = np.quantile(dists,qu)\n",
    "    wh = np.where(dists<=quant)[0]\n",
    "    \n",
    "    return(list(wh))\n",
    "\n",
    "def get_cluster_data(adata,cluster,ng,mode,add_tf='no'):\n",
    "    \n",
    "    # Description:\n",
    "    # Extracts from the full data set all the information required to predict\n",
    "    # the network for each cluster\n",
    "    # Input:\n",
    "    #   - X = numpy array, original expression matrix\n",
    "    #   - V = numpy array, original velocity matrix\n",
    "    #   - G = numpy diagonal matrix, gamma matrix of all the genes\n",
    "    #   - G_annot = data fram with gene annotations\n",
    "    #   - ind = index to select cells from the specified cluster \n",
    "    #   - ng = int, number of genes to choose\n",
    "    #   - mode = str, gene selection method \n",
    "    #   - cluster = str, name of cluster \n",
    "    \n",
    "    ind = adata.obs[clustcol] == cluster\n",
    "    \n",
    "    #Velocity matrix\n",
    "    V_c = adata.layers[\"velocity\"][ind.values,:]\n",
    "    V_non_nan = np.where(np.logical_not(np.isnan(V_c.sum(axis=0))))[0].tolist()\n",
    "    genes_valid = adata.var[['velocity_genes']].iloc[V_non_nan,:].index\n",
    "    V_c = pd.DataFrame(V_c[:,V_non_nan],columns=genes_valid)\n",
    "    \n",
    "    #Expression matrix\n",
    "    X_c = pd.DataFrame(adata.layers['spliced'][:,V_non_nan][ind.values,:].todense(),columns=genes_valid)\n",
    "\n",
    "    #Select top n genes and filter matrices\n",
    "    fg = grn_selectGenes(V_c,X_c,ng,mode=mode)\n",
    "    \n",
    "    if add_tf=='yes':\n",
    "        fg = utl_unique(fg + grn_selectTFs(adata,c))\n",
    "    \n",
    "    #Filter matrices for model reconstruction \n",
    "    \n",
    "    genes = [g for g in fg if g in X_c.columns]\n",
    "    X_c_f = X_c.loc[:,genes] # cell by gene expression matrix\n",
    "    V_c_f = V_c.loc[:,genes] # cell by gene velocity matrix\n",
    "    G_f = np.diag(adata.var.fit_gamma[V_non_nan].loc[genes,]) # gene by gene diagonal gamma matrix\n",
    "\n",
    "    X_d = pd.DataFrame(np.array(X_c_f,dtype=np.float64),columns = genes)\n",
    "    V_c_f = V_c_f.fillna(0)\n",
    "    \n",
    "    return(X_c_f,X_d,V_c_f,G_f,genes)\n",
    "    \n",
    "def predict_network(Xc,Vc,Gf,fg):\n",
    "    \n",
    "    Xpinv = np.linalg.pinv(Xc)\n",
    "    W = np.dot(Xpinv,(Vc + np.dot(Xc,Gf)))\n",
    "    W = np.nan_to_num(W,nan=0)  # Set to zero the weights that could not be inferred \n",
    "    W_d = pd.DataFrame(np.array(W,dtype=np.float64),index=fg,columns=fg)\n",
    "    \n",
    "    return(W,W_d)   \n",
    "\n",
    "def select_TFs(adata,c):\n",
    "    \n",
    "    exp_tf = adata.uns['expressed_TF']\n",
    "    ad_ctf = adata[adata.obs[clustcol]== c,exp_tf]\n",
    "    ad_ctf.var['cluster'] = 1\n",
    "    exp_med = np.array(np.mean(ad_ctf.layers['spliced'].todense(),axis=0)).reshape(len(exp_tf),1)\n",
    "\n",
    "    tf_dat = pd.DataFrame(exp_med,index=exp_tf,columns={'mean_expression'})\n",
    "    tf_dat['mean_velocity'] = np.abs(np.mean(ad_ctf.layers['velocity'],axis=0)).reshape(len(exp_tf),1)\n",
    "    tf_dat.fillna(0,inplace=True)\n",
    "    tf_dat = tf_dat[[not(b1 and b2) for b1,b2 in zip(tf_dat['mean_expression']==0,tf_dat['mean_velocity']==0)]]\n",
    "    \n",
    "    tf_ranks = tf_dat.rank()\n",
    "    tf_ranks['mean'] = np.average(tf_ranks,axis=1,weights=np.array([0.3,0.7]))\n",
    "    tf_ranks.columns = [col+'_rank'for col in tf_ranks.columns]\n",
    "\n",
    "    tf_dat = pd.concat([tf_dat,tf_ranks],axis=1).sort_values(by='mean_rank',ascending=False)\n",
    "    tf_dat['included'] = tf_dat['mean_rank']>=np.quantile(tf_dat['mean_rank'],0.65)\n",
    "\n",
    "\n",
    "    top_tf = tf_dat.index[tf_dat['included']].tolist()\n",
    "\n",
    "    return(top_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
